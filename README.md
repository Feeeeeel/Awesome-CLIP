# Awesome CLIP 
This repo collects the Applications of CLIP (Contrastive Language-Image Pre-Training) proposed by OpenAI. 



Collect some CLIP with Computer-Vision (CV) papers.

If you find some overlooked papers, please open issues or pull requests (recommended).





## Original Repo
https://openai.com/blog/clip/


## Training of CLIP
- Train-CLIP (3rd-party, PyTorch) [[code](https://github.com/Zasder3/train-CLIP)] 
- Paddle-CLIP (3rd-party, PaddlePaddle)[[code](https://github.com/Zasder3/train-CLIP)] 

## Applications
- VQGAN-CLIP (https://github.com/nerdyrodent/VQGAN-CLIP)

## Detection
- Roboflow Object Tracking [[code](https://github.com/roboflow-ai/zero-shot-object-tracking)] 
- Zero-Shot Detection via Vision and Language Knowledge Distillation (3rd party) [[code](https://github.com/llrtt/Zero-Shot-Detection-via-Vision-and-Language-Knowledge-Distillation)]

## Image Retrival 
- Unsplash Image Search [[code](https://github.com/haltakov/natural-language-image-search)]


You are welcome to contribute this repo! Please contact yzhuoning@gmail.com or open an issue. Thanks!

## Acknowledgement
Thanks the template from [Awesome Visual-Transformer](https://github.com/dk-liang/Awesome-Visual-Transformer).
