# Awesome CLIP 
This repo collects the resources of CLIP (Contrastive Language-Image Pre-Training) proposed by OpenAI. If you find this repo useful, please star this repo. If you would like to contribute, please open issues or pull requests.

## CLIP 
- Learning Transferable Visual Models From Natural Language Supervision [[paper](https://arxiv.org/abs/2103.00020)][[code](https://github.com/openai/CLIP)]
- CLIP: Connecting Text and Images [[blog](https://openai.com/blog/clip/)]

## Training CLIP
- Train-CLIP (3rd-party, PyTorch) [[code](https://github.com/Zasder3/train-CLIP)] 
- Paddle-CLIP (3rd-party, PaddlePaddle) [[code](https://github.com/Zasder3/train-CLIP)] 

## Applications

### GAN 
- VQGAN-CLIP [[code](https://github.com/nerdyrodent/VQGAN-CLIP)]
- StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery [[paper](https://arxiv.org/abs/2103.17249)][[code](https://github.com/orpatashnik/StyleCLIP)]
- CLIP Guided Diffusion [[code](https://github.com/afiaka87/clip-guided-diffusion)] 

### Detection
- Roboflow Object Tracking [[code](https://github.com/roboflow-ai/zero-shot-object-tracking)] 
- Zero-Shot Detection via Vision and Language Knowledge Distillation [[paper](https://arxiv.org/abs/2104.13921)][[code*](https://github.com/llrtt/Zero-Shot-Detection-via-Vision-and-Language-Knowledge-Distillation)]

### Information Retrieval
- Unsplash Image Search [[code](https://github.com/haltakov/natural-language-image-search)]
- CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval [[paper](https://arxiv.org/abs/2104.08860)][[code](https://github.com/ArrowLuo/CLIP4Clip)]
- Less is More: ClipBERT for Video-and-Language Learning via Sparse Sampling [[paper](https://arxiv.org/abs/2102.06183)][[code](https://github.com/jayleicn/ClipBERT)]


## Acknowledgment
[Awesome Visual-Transformer](https://github.com/dk-liang/Awesome-Visual-Transformer).
