# Awesome CLIP 
This repo collects the resources of CLIP (Contrastive Language-Image Pre-Training) proposed by OpenAI. If you find this repo useful, please give me a star. If you would like to contribute, please open issues or pull requests or drop me an email yzhuoning@gmail.com.

## CLIP
- Learning Transferable Visual Models From Natural Language Supervision [[link](https://arxiv.org/abs/2103.00020)]
- CLIP: Connecting Text and Images [[blog](https://openai.com/blog/clip/)]
- Github [[code](https://github.com/openai/CLIP)]

## Training CLIP
- Train-CLIP (3rd-party, PyTorch) [[code](https://github.com/Zasder3/train-CLIP)] 
- Paddle-CLIP (3rd-party, PaddlePaddle)[[code](https://github.com/Zasder3/train-CLIP)] 

## Applications

### GAN 
- VQGAN-CLIP [[code](https://github.com/nerdyrodent/VQGAN-CLIP)]

### Detection
- Roboflow Object Tracking [[code](https://github.com/roboflow-ai/zero-shot-object-tracking)] 
- Zero-Shot Detection via Vision and Language Knowledge Distillation [[paper](https://arxiv.org/abs/2104.13921)][[code](https://github.com/llrtt/Zero-Shot-Detection-via-Vision-and-Language-Knowledge-Distillation)](3rd party)

## Image Retrival 
- Unsplash Image Search [[code](https://github.com/haltakov/natural-language-image-search)]

## Acknowledgement
Thanks the template from [Awesome Visual-Transformer](https://github.com/dk-liang/Awesome-Visual-Transformer).
